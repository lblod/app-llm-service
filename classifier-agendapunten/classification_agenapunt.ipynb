{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "def extract_json_formatted( response):\n",
    "    #remove trailing and leading json formatting\n",
    "    response_text = clean_json_string(response)\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Skipping invalid JSON in response: {response_text}\")\n",
    "        return None\n",
    "    \n",
    "def clean_json_string(json_string):\n",
    "        pattern = r'^```json\\s*(.*?)\\s*```$'\n",
    "        cleaned_string = re.sub(pattern, r'\\1', json_string, flags=re.DOTALL)\n",
    "        return cleaned_string.strip()\n",
    "\n",
    "def read_jsonl_and_append_data(file_path, data_storage):\n",
    "    \"\"\"\n",
    "    Reads a JSONL file and appends parsed data to the provided data storage list.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the JSONL file.\n",
    "    - data_storage: List to append the parsed data to.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON line\n",
    "            sample = json.loads(line)\n",
    "            # Append a structured object to the data storage\n",
    "            data_storage.append({\n",
    "                'data': json.loads(sample['user_input']),\n",
    "                'labels': extract_json_formatted(sample['response'])\n",
    "            })\n",
    "\n",
    "# Example usage:\n",
    "data_array = []\n",
    "file_path = 'classification_agendapunt_openai_dataset.jsonl'\n",
    "read_jsonl_and_append_data(file_path, data_array)\n",
    "\n",
    "file_path = 'classification_agendapunt_openai_dataset_meta.jsonl'\n",
    "read_jsonl_and_append_data(file_path, data_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data_array:  4993\n",
      "data_array[0]:  {'data': {'uri': 'https://data.gent.be/id/agendapunten/22.0215.3724.2149', 'title': '2022_RMW_00022 - Samenwerkingsovereenkomst betreffende Vlaamse Housing First middelen voor CAW Oost-Vlaanderen - Goedkeuring', 'description': 'Aan de raad voor maatschappelijk welzijn wordt gevraagd goedkeuring te verlenen aan de Samenwerkingsovereenkomst met Centrum voor Algemeen Welzijnswerk vzw, Visserij 153, 9000 Gent betreffende Vlaamse Housing First middelen voor CAW Oost-Vlaanderen.\\r\\n'}, 'labels': {'classification': {'stadsbestuur': ['samenwerkingsovereenkomst'], 'samenleven, welzijn en gezondheid': ['dak- en thuisloosheid', 'welzijnswerk']}}}\n"
     ]
    }
   ],
   "source": [
    "print(\"length of data_array: \", len(data_array))\n",
    "print(\"data_array[0]: \", data_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  ['burgerzaken', 'stadsbestuur', 'cultuur, sport en vrije tijd', 'mobiliteit en openbare werken', 'groen en milieu', 'onderwijs en kinderopvang', 'samenleven, welzijn en gezondheid', 'werken en ondernemen', 'wonen en (ver)bouwen']\n"
     ]
    }
   ],
   "source": [
    "taxonomy = json.loads(open(r'..\\source\\taxonomy_agendapunten.json').read())\n",
    "classes = list(taxonomy.keys())\n",
    "print(\"classes: \", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the spacy training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of label_distribution (top-levels):  10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'label_distribution (top-levels): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'stadsbestuur': 2662,\n",
       " 'samenleven, welzijn en gezondheid': 241,\n",
       " 'wonen en (ver)bouwen': 782,\n",
       " 'groen en milieu': 215,\n",
       " 'mobiliteit en openbare werken': 693,\n",
       " 'cultuur, sport en vrije tijd': 607,\n",
       " 'werken en ondernemen': 59,\n",
       " 'onderwijs en kinderopvang': 229,\n",
       " 'burgerzaken': 91,\n",
       " 'veiligheid en preventie': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print distribution of labels\n",
    "\n",
    "label_distribution = {}\n",
    "\n",
    "for data in data_array:\n",
    "    labels = data['labels'][\"classification\"]\n",
    "    if labels:\n",
    "        for label in labels:\n",
    "            if label in label_distribution:\n",
    "                label_distribution[label] += 1\n",
    "            else:\n",
    "                label_distribution[label] = 1\n",
    "\n",
    "                \n",
    "print(\"length of label_distribution (top-levels): \", len(label_distribution))\n",
    "display(\"label_distribution (top-levels): \", label_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing datasets created and saved.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "import random\n",
    "\n",
    "nlp = spacy.blank(\"nl\")  # Assuming Dutch language model\n",
    "\n",
    "# Assuming 'classes' list is defined and populated with all possible classes\n",
    "\n",
    "spacy_data = []\n",
    "for data in data_array:\n",
    "    text = data['data']['title'] + \" \" + data['data']['description']\n",
    "    labels = list(data['labels']['classification'].keys())  # Adjust according to your data structure\n",
    "    # Initialize all classes to 0\n",
    "    cats = {label: 0 for label in classes}\n",
    "    # Set the class to 1 if it's present in the labels\n",
    "    for label in labels:\n",
    "        if label in classes:\n",
    "            cats[label] = 1\n",
    "    # Check if at least one class is assigned\n",
    "    if any(cats.values()):\n",
    "        spacy_data.append((text, {\"cats\": cats}))\n",
    "\n",
    "# Shuffle the data to ensure random distribution\n",
    "random.shuffle(spacy_data)\n",
    "\n",
    "# Split the data (e.g., 80% train, 20% test)\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(spacy_data) * split_ratio)\n",
    "train_data = spacy_data[:split_index]\n",
    "test_data = spacy_data[split_index:]\n",
    "\n",
    "# Function to create a DocBin from data\n",
    "def create_docbin(data, nlp):\n",
    "    doc_bin = DocBin(attrs=[\"LEMMA\", \"ENT_IOB\", \"ENT_TYPE\"], store_user_data=True)\n",
    "    for text, annotations in data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        doc_bin.add(example.reference)\n",
    "    return doc_bin\n",
    "\n",
    "# Create DocBin for both train and test data\n",
    "train_doc_bin = create_docbin(train_data, nlp)\n",
    "test_doc_bin = create_docbin(test_data, nlp)\n",
    "\n",
    "# Save the DocBins to files\n",
    "train_doc_bin.to_disk(\"./spacy_textcat_train.spacy\")\n",
    "test_doc_bin.to_disk(\"./spacy_textcat_test.spacy\")\n",
    "\n",
    "print(\"Training and testing datasets created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021_CBS_01153 - 2021/00226M - Aktename melding voor het bouwen van een veranda langs Berkenstraat 3 in 3950 Bocholt - Goedkeuring Aktename melding voor het bouwen van een veranda langs de Berkenstraat\n",
      "Categories: {'burgerzaken': 0, 'stadsbestuur': 0, 'cultuur, sport en vrije tijd': 0, 'mobiliteit en openbare werken': 0, 'groen en milieu': 0, 'onderwijs en kinderopvang': 0, 'samenleven, welzijn en gezondheid': 0, 'werken en ondernemen': 0, 'wonen en (ver)bouwen': 1}\n",
      "---\n",
      "2022_CBS_00895 - Bestelbonnen 2022 week 19: goedkeuring  \n",
      "Categories: {'burgerzaken': 0, 'stadsbestuur': 1, 'cultuur, sport en vrije tijd': 0, 'mobiliteit en openbare werken': 0, 'groen en milieu': 0, 'onderwijs en kinderopvang': 0, 'samenleven, welzijn en gezondheid': 0, 'werken en ondernemen': 0, 'wonen en (ver)bouwen': 0}\n",
      "---\n",
      "11.  Onteigeningsplan Grotestraat (vanaf Warvinge tot grens met Zuienkerke) - Definitief onteigeningsbesluit \n",
      "Categories: {'burgerzaken': 0, 'stadsbestuur': 0, 'cultuur, sport en vrije tijd': 0, 'mobiliteit en openbare werken': 0, 'groen en milieu': 0, 'onderwijs en kinderopvang': 0, 'samenleven, welzijn en gezondheid': 0, 'werken en ondernemen': 0, 'wonen en (ver)bouwen': 1}\n",
      "---\n",
      "Renovatie asbesthoudend dak gemeentelijke loods - onderhandelingsprocedure zonder voorafgaande bekendmaking - goedkeuring lastvoorwaarden en gunningswijze \n",
      "Categories: {'burgerzaken': 0, 'stadsbestuur': 1, 'cultuur, sport en vrije tijd': 0, 'mobiliteit en openbare werken': 0, 'groen en milieu': 0, 'onderwijs en kinderopvang': 0, 'samenleven, welzijn en gezondheid': 0, 'werken en ondernemen': 0, 'wonen en (ver)bouwen': 1}\n",
      "---\n",
      "2021_CBS_00359 - Buitengewone herstelling wegen in asfalt - Dienstjaar 2020 - Aanvangsdatum - Goedkeuring Het college van burgemeester en schepenen wordt gevraagd om het aanvangsbevel van 29.03.2021 voor de betonwerken en het aanvangsbevel van 12.04.2021 voor de asfaltwerken voor de opdracht \"Buitengewone herstelling wegen in asfalt - Dienstjaar 2020\" goed te keuren.\n",
      "\n",
      "Categories: {'burgerzaken': 0, 'stadsbestuur': 0, 'cultuur, sport en vrije tijd': 0, 'mobiliteit en openbare werken': 1, 'groen en milieu': 0, 'onderwijs en kinderopvang': 0, 'samenleven, welzijn en gezondheid': 0, 'werken en ondernemen': 0, 'wonen en (ver)bouwen': 0}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Load the test DocBin\n",
    "test_doc_bin = DocBin().from_disk(\"./spacy_textcat_test.spacy\")\n",
    "\n",
    "# Load the docs from the DocBin\n",
    "test_docs = list(test_doc_bin.get_docs(nlp.vocab))\n",
    "\n",
    "# Print 5 samples\n",
    "for doc in test_docs[:5]:\n",
    "    print(doc.text)\n",
    "    print(\"Categories:\", doc.cats)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the config file and train the model using the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m train config.cfg --paths.train ./spacy_textcat_train.spacy --paths.dev ./spacy_textcat_test.spacy --output ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"../robbert-2023-abb-agendapunten-classifier/model-best\")\n",
    "\n",
    "text = \"\"\"\n",
    "2021_CBS_01153 - 2021/00226M - Aktename melding voor het bouwen van een veranda langs Berkenstraat 3 in 3950 Bocholt - Goedkeuring Aktename melding voor het bouwen van een veranda langs de Berkenstraat\n",
    "\"\"\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(doc.cats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abbNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
